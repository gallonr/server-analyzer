# ğŸš€ Guide de DÃ©marrage - Server Analyzer

**Projet** : SystÃ¨me d'analyse et de visualisation de l'arborescence serveur 28 To  
**Version** : 1.0  
**Date** : 4 octobre 2025  
**Statut** : âœ… Production Ready (Phases 0 Ã  3 complÃ¨tes)

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble](#-vue-densemble)
2. [Installation](#-installation)
3. [Configuration](#-configuration)
4. [DÃ©ploiement serveur](#-dÃ©ploiement-serveur)
5. [Utilisation](#-utilisation)
6. [Dashboard](#-dashboard)
7. [Exports et comparaisons](#-exports-et-comparaisons)
8. [RÃ©solution de problÃ¨mes](#-rÃ©solution-de-problÃ¨mes)

---

## ğŸ¯ Vue d'ensemble

### CapacitÃ©s du systÃ¨me

Le Server Analyzer est un programme Python performant capable de :

- âœ… Scanner et analyser **10-20 millions de fichiers** (28 To)
- âœ… Extraire les mÃ©tadonnÃ©es complÃ¨tes (permissions, propriÃ©taires, dates, tailles)
- âœ… Stocker de maniÃ¨re optimisÃ©e dans SQLite avec indexation
- âœ… Scan parallÃ©lisÃ© avec **80 workers** sur serveur de calcul
- âœ… Visualisation interactive avec dashboard Streamlit
- âœ… Exploration arborescence avec navigation drill-down
- âœ… Filtres dynamiques (taille, extension, propriÃ©taire, date, nom)
- âœ… Exports multi-formats (CSV, Excel, JSON)
- âœ… Comparaison entre scans successifs
- âœ… DÃ©tection d'anomalies (gros fichiers, fichiers anciens, doublons)

### Phases rÃ©alisÃ©es

- âœ… **Phase 0** : Structure projet et environnement (2h)
- âœ… **Phase 1** : Scanner core et stockage (2h)
- âœ… **Phase 2** : Statistiques et analyses (1h)
- âœ… **Phase 3.1** : Dashboard - Vue d'ensemble (1 jour)
- âœ… **Phase 3.2** : Dashboard - Explorateur et filtres (1 jour)
- âœ… **Phase 3.3** : Dashboard - Comparaisons et exports (1 jour)

### Serveur de production

**Serveur distant** : `user@domaine`  
**CaractÃ©ristiques** : 20-80 cÅ“urs CPU, 16-32 Go RAM, Python 3.12

---

## ğŸ“¦ Installation

### PrÃ©-requis

- Python 3.10 ou supÃ©rieur
- 16-32 Go RAM
- AccÃ¨s SSH au serveur (pour dÃ©ploiement distant)

### Installation locale (dÃ©veloppement/tests)

```bash
# 1. Cloner/tÃ©lÃ©charger le projet
cd /chemin/vers/server-analyzer

# 2. CrÃ©er environnement virtuel
python3 -m venv venv

# 3. Activer l'environnement virtuel
source venv/bin/activate  # Linux/macOS
# ou
venv\Scripts\activate  # Windows

# 4. Mettre Ã  jour pip
pip install --upgrade pip setuptools wheel

# 5. Installer les dÃ©pendances
pip install -r requirements.txt

# 6. VÃ©rifier l'installation
python -c "import pandas, streamlit, plotly; print('âœ… Installation OK')"
```

### Installation sur le serveur

Voir section [DÃ©ploiement serveur](#-dÃ©ploiement-serveur)

---

## âš™ï¸ Configuration

### Fichier config.yaml

Le fichier `config.yaml` contrÃ´le tous les aspects du scan :

```bash
# 1. Copier l'exemple (premiÃ¨re fois)
cp config.yaml.example config.yaml

# 2. Ã‰diter la configuration
nano config.yaml
```

### Structure de config.yaml

```yaml
# Chemins racine Ã  scanner
root_paths:
  - "/data/archives"
  - "/home/shared"

# Exclusions
exclusions:
  directories:
    - ".git"
    - "__pycache__"
    - "venv"
  extensions:
    - ".tmp"
    - ".cache"

# Performance
performance:
  num_workers: 80          # Nombre de processus parallÃ¨les
  batch_size: 50000        # Taille des lots d'insertion
  queue_size: 1000         # Taille de la queue
  checkpoint_interval: 100000  # Sauvegarde tous les N fichiers

# Base de donnÃ©es
database:
  path: "data/server_analysis.db"
  
# Statistiques
stats:
  large_file_threshold_gb: 10    # Seuil fichier volumineux
  old_file_threshold_days: 730   # Seuil fichier ancien (2 ans)
  enable_duplicate_detection: true
```

### Valider la configuration

```bash
source venv/bin/activate
python src/config_validator.py
```

**Sortie attendue** :
```
âœ… Configuration valide
ğŸ“‹ Chemins Ã  scanner: 2
ğŸš« Exclusions: 5 dossiers, 2 extensions
âš™ï¸  Workers: 80, Batch: 50000
```

---

## ğŸŒ DÃ©ploiement serveur

### MÃ©thode automatique (recommandÃ©e)

Le script `deploy.sh` automatise le dÃ©ploiement complet :

```bash
# Sur votre machine locale
cd /chemin/vers/server-analyzer
./deploy.sh
```

**Ce que fait le script** :
1. âœ… VÃ©rifie la connexion SSH
2. âœ… CrÃ©e le rÃ©pertoire distant `~/server-analyzer`
3. âœ… Synchronise tous les fichiers (exclut venv, cache, data)
4. âœ… Installe `python3-venv` si nÃ©cessaire (avec sudo)
5. âœ… CrÃ©e l'environnement virtuel distant
6. âœ… Installe toutes les dÃ©pendances Python
7. âœ… CrÃ©e la structure de dossiers (data, logs, checkpoints)
8. âœ… Copie `config.yaml.example` â†’ `config.yaml`

### âš ï¸ Important : Environnement virtuel

Sur les systÃ¨mes Debian/Ubuntu rÃ©cents (Python 3.12+), **vous DEVEZ utiliser un environnement virtuel** pour installer des packages Python.

**âŒ NE PAS FAIRE** :
```bash
# Ceci Ã©chouera avec "externally-managed-environment"
pip install streamlit
```

**âœ… FAIRE** :
```bash
# Toujours activer le venv d'abord
cd ~/server-analyzer
source venv/bin/activate
# Maintenant vous pouvez utiliser pip
pip install <package>
```

### Configuration post-dÃ©ploiement

```bash
# 1. Se connecter au serveur
ssh user@domaine

# 2. Aller dans le dossier
cd ~/server-analyzer

# 3. Activer l'environnement virtuel
source venv/bin/activate

# 4. Ã‰diter la configuration pour le serveur
nano config.yaml

# 5. Adapter les chemins (exemple pour serveur 28 To)
# root_paths:
#   - "/data/archives"
#   - "/data/projects"

# 6. Tester la configuration
python src/config_validator.py
```

### Scripts utilitaires

```bash
# Connexion SSH rapide
./connect.sh

# Activer l'environnement virtuel (local ou distant)
source activate.sh
# ou
./activate.sh
```

---

## ğŸ” Utilisation

### 1. Lancer un scan complet

```bash
# Sur le serveur (aprÃ¨s connexion SSH)
cd ~/server-analyzer
source venv/bin/activate

# Lancer le scan (utilise config.yaml)
python scripts/run_scan.py

# Ou avec configuration personnalisÃ©e
python scripts/run_scan.py --config config_production.yaml
```

**Exemple de sortie** :
```
ğŸš€ Scan dÃ©marrÃ©
ğŸ“‚ Chemins : /data/archives, /data/projects
âš™ï¸  Workers : 80
ğŸ’¾ Base de donnÃ©es : data/server_analysis.db

Progression: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4,523,891/4,523,891 [12:34<00:00, 6000 files/s]

âœ… Scan terminÃ© avec succÃ¨s!
ğŸ“Š RÃ©sultats: 4,523,891 fichiers, 12.5 TB
ğŸ’¾ Base de donnÃ©es: data/server_analysis.db
â±ï¸  DurÃ©e: 12m 34s
ğŸš€ DÃ©bit: 6,000 fichiers/seconde

ğŸ“Š Calcul des statistiques...
âœ… Statistiques calculÃ©es
```

### 2. Test local (dÃ©veloppement)

```bash
# Sur votre machine locale
source venv/bin/activate

# Utiliser la configuration de test
python scripts/run_scan.py --config config_test_local.yaml
```

### 3. Options du scanner

```bash
# Voir toutes les options
python scripts/run_scan.py --help

# Options principales :
--config CONFIG    # Fichier de configuration (dÃ©faut: config.yaml)
--skip-stats       # Ne pas calculer les statistiques aprÃ¨s le scan
--resume           # Reprendre un scan interrompu (checkpoint)
```

### 4. Gestion des scans longs

Pour les scans trÃ¨s longs (plusieurs heures), utilisez `screen` ou `tmux` :

```bash
# CrÃ©er une session screen
screen -S scan_serveur

# Lancer le scan
cd ~/server-analyzer
source venv/bin/activate
python scripts/run_scan.py

# DÃ©tacher la session : Ctrl+A puis D
# Vous pouvez vous dÃ©connecter, le scan continue

# Revenir Ã  la session plus tard
screen -r scan_serveur
```

---

## ğŸ“Š Dashboard

### Lancer le dashboard

```bash
# Sur le serveur (ou en local)
cd ~/server-analyzer
source venv/bin/activate

# MÃ©thode 1 : Script automatique
./scripts/start_dashboard.sh

# MÃ©thode 2 : Commande directe
streamlit run src/dashboard/app.py
```

**URL** : `http://localhost:8501` (local)

### AccÃ¨s distant au dashboard

Si le dashboard tourne sur le serveur, crÃ©ez un tunnel SSH :

```bash
# Sur votre machine locale
ssh -L 8501:localhost:8501 user@domaine

# Puis ouvrir dans votre navigateur
# http://localhost:8501
```

### Pages du dashboard

Le dashboard contient 4 pages principales :

#### 1. ğŸ  Vue d'ensemble

**MÃ©triques principales** (4 cards) :
- Total fichiers scannÃ©s
- Taille totale du serveur
- Nombre de dossiers
- DurÃ©e du dernier scan

**Graphiques standards** :
- ğŸ“Š Top 10 extensions (bar chart)
- ğŸ‘¤ Top 10 propriÃ©taires (bar chart)
- ğŸ“ Distribution des tailles (histogram)

**Graphiques avancÃ©s** :
- ğŸ¥§ Pie chart rÃ©partition par extension
- ğŸŒ³ Treemap volumes hiÃ©rarchiques
- ğŸ“… Timeline distribution temporelle

#### 2. ğŸ“ Explorateur

**Navigation arborescence** :
- SÃ©lection dossier racine
- Navigation drill-down (clic sur sous-dossier)
- Bouton "Dossier parent" (remontÃ©e)
- Breadcrumb (chemin complet)
- Stats dossier courant (fichiers, taille, top extensions)

**Tableau fichiers** :
- Colonnes : Nom, Taille, PropriÃ©taire, Groupe, Date, Permissions, Extension
- Tri par taille dÃ©croissant
- Pagination (50/100/500/1000 fichiers par page)
- Export CSV (page courante ou complet)

**Filtres dynamiques (sidebar)** :
- ğŸ’¾ **Taille** : Plage min/max (MB)
- ğŸ“„ **Extension** : SÃ©lection multiple
- ğŸ‘¤ **PropriÃ©taire** : SÃ©lection multiple
- ğŸ“… **Date modification** : Plage de dates
- ğŸ”¤ **Nom fichier** : Pattern de recherche

Boutons :
- âœ… Appliquer (applique filtres et recharge)
- ğŸ”„ RÃ©initialiser (supprime tous filtres)

#### 3. ğŸ“¤ Exports

**3 formats d'export disponibles** :

1. **CSV** : Format universel, lÃ©ger
   - Une ligne par fichier
   - Toutes les mÃ©tadonnÃ©es

2. **Excel** : Format professionnel avec formatage
   - Feuille "Informations" : mÃ©tadonnÃ©es du scan
   - Feuille "Fichiers" : liste complÃ¨te avec mise en forme
   - Feuille "Extensions" : statistiques par extension
   - Formatage automatique (tailles, dates, couleurs)

3. **JSON** : Format structurÃ© pour traitement programmatique
   - MÃ©tadonnÃ©es scan
   - Liste fichiers
   - Stats par extension

**Options** :
- âœ… Appliquer les filtres actifs (exporte seulement les fichiers filtrÃ©s)
- Bouton tÃ©lÃ©chargement direct

#### 4. ğŸ”„ Comparaisons

**Comparer 2 scans** :
- SÃ©lection de 2 scans dans la base
- Validation automatique (scans diffÃ©rents)

**MÃ©triques d'Ã©volution** :
- Î” Nombre de fichiers
- Î” Volume total
- Pourcentages d'Ã©volution

**Graphiques** :
- ğŸ“ˆ Ã‰volution (double axe : nb fichiers + volume)
- ğŸ¥§ Pie chart catÃ©gories de changements

**DÃ©tails par catÃ©gorie (3 tabs)** :
- âœ… **Nouveaux fichiers** : fichiers ajoutÃ©s
- âŒ **Fichiers supprimÃ©s** : fichiers retirÃ©s
- ğŸ”„ **Fichiers modifiÃ©s** : fichiers dont taille/date a changÃ©

Chaque tab :
- Tableau paginÃ© avec dÃ©tails
- Export CSV de la catÃ©gorie

---

## ğŸ“ Exports et comparaisons

### Export CLI (sans dashboard)

Le script `export_results.py` permet d'exporter en ligne de commande :

```bash
source venv/bin/activate

# Lister les scans disponibles
python scripts/export_results.py --list

# Exporter en CSV
python scripts/export_results.py --scan-id 1 --format csv

# Exporter en Excel
python scripts/export_results.py --scan-id 1 --format excel

# Exporter en JSON
python scripts/export_results.py --scan-id 1 --format json

# SpÃ©cifier le fichier de sortie
python scripts/export_results.py --scan-id 1 --format csv --output mon_export.csv
```

**Sortie par dÃ©faut** : `data/exports/scan_<id>_<timestamp>.<format>`

### Comparaison CLI

Le script `compare_scans.py` permet de comparer 2 scans :

```bash
source venv/bin/activate

# Comparer scan 1 et scan 2
python scripts/compare_scans.py 1 2

# Avec export CSV des diffÃ©rences
python scripts/compare_scans.py 1 2 --export
```

**Sortie** :
```
ğŸ”„ Comparaison des scans

Scan 1 : 2025-10-01 14:23:45 (1,234,567 fichiers)
Scan 2 : 2025-10-04 09:15:32 (1,256,789 fichiers)

ğŸ“Š RÃ©sultats :
  âœ… Nouveaux      : 25,000 fichiers (+1.2 TB)
  âŒ SupprimÃ©s     : 2,778 fichiers (-0.3 TB)
  ğŸ”„ ModifiÃ©s      : 15,432 fichiers
  
Fichiers exportÃ©s :
  - data/exports/new_files.csv
  - data/exports/deleted_files.csv
  - data/exports/modified_files.csv
```

---

## ğŸ§ª Tests

### ExÃ©cuter tous les tests

```bash
source venv/bin/activate

# Tous les tests avec couverture
pytest tests/ -v --cov=src

# Tests spÃ©cifiques
pytest tests/test_scanner.py -v
pytest tests/test_database.py -v
pytest tests/test_stats.py -v
pytest tests/test_integration.py -v
```

### Tests de performance

```bash
# Test performance scanner
pytest tests/test_performance.py -v

# Test avec profiling
pytest tests/test_performance.py -v --profile
```

**RÃ©sultats attendus** :
```
Tests totaux : 70/70 âœ…
Couverture   : 76%
DurÃ©e        : ~10 secondes
```

---

## ğŸ› RÃ©solution de problÃ¨mes

### Erreur : externally-managed-environment

**SymptÃ´me** :
```
error: externally-managed-environment
Ã— This environment is externally managed
```

**Cause** : Installation pip en dehors d'un environnement virtuel sur Debian/Ubuntu

**Solution** :
```bash
# TOUJOURS activer le venv d'abord
cd ~/server-analyzer
source venv/bin/activate
# Puis installer
pip install <package>
```

### Erreur : python3-venv non installÃ©

**SymptÃ´me** :
```
The virtual environment was not created successfully because ensurepip is not available.
```

**Solution** :
```bash
# Installer python3-venv
sudo apt update
sudo apt install python3-venv python3-full

# Puis recrÃ©er le venv
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### Dashboard ne se lance pas

**SymptÃ´me** :
```
ModuleNotFoundError: No module named 'streamlit'
```

**Cause** : venv non activÃ© ou dÃ©pendances non installÃ©es

**Solution** :
```bash
cd ~/server-analyzer
source venv/bin/activate
pip install -r requirements.txt
streamlit run src/dashboard/app.py
```

### Scan trÃ¨s lent

**SymptÃ´me** : DÃ©bit < 1000 fichiers/seconde

**Solutions** :
1. Augmenter le nombre de workers dans `config.yaml` :
   ```yaml
   performance:
     num_workers: 80  # Adapter au nombre de cÅ“urs
   ```

2. Exclure les dossiers inutiles :
   ```yaml
   exclusions:
     directories:
       - ".git"
       - "__pycache__"
       - "node_modules"
       - ".cache"
   ```

3. Utiliser un SSD pour la base de donnÃ©es

### Base de donnÃ©es corrompue

**SymptÃ´me** :
```
sqlite3.DatabaseError: database disk image is malformed
```

**Solution** :
```bash
# Sauvegarder l'ancienne base
mv data/server_analysis.db data/server_analysis.db.backup

# Relancer un scan complet
python scripts/run_scan.py
```

### Scan interrompu

**SymptÃ´me** : Scan arrÃªtÃ© (Ctrl+C, connexion perdue, etc.)

**Solution** :
```bash
# Le scan reprendra automatiquement au dernier checkpoint
python scripts/run_scan.py --resume
```

### ProblÃ¨me de connexion SSH

**SymptÃ´me** :
```
ssh: connect to host 192.168.1.158 port 22: Connection refused
```

**Solutions** :
1. VÃ©rifier la connexion rÃ©seau
2. VÃ©rifier que le serveur est accessible
3. Consulter `SSH_GUIDE.md` pour configurer les clÃ©s SSH

---

## ğŸ“š Documentation complÃ©mentaire

- **README.md** : Vue d'ensemble gÃ©nÃ©rale
- **SSH_GUIDE.md** : Configuration SSH et connexion serveur
- **SERVEUR_CONFIG.md** : Configuration spÃ©cifique serveur
- **DASHBOARD_QUICKSTART.md** : Guide rapide dashboard
- **PHASE*_RAPPORT.md** : Rapports techniques dÃ©taillÃ©s par phase

---

## ğŸ¯ Workflow complet recommandÃ©

### PremiÃ¨re utilisation

1. **Installation locale (test)** :
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   python scripts/run_scan.py --config config_test_local.yaml
   ./scripts/start_dashboard.sh
   ```

2. **DÃ©ploiement serveur** :
   ```bash
   ./deploy.sh
   ssh user@domaine
   cd ~/server-analyzer
   source venv/bin/activate
   nano config.yaml  # Configurer les chemins
   ```

3. **Premier scan serveur** :
   ```bash
   screen -S scan
   python scripts/run_scan.py
   # Ctrl+A D (dÃ©tacher)
   ```

4. **Visualisation** :
   ```bash
   # Tunnel SSH depuis votre machine locale
   ssh -L 8501:localhost:8501 user@domaine
   
   # Sur le serveur
   ./scripts/start_dashboard.sh
   
   # Navigateur local : http://localhost:8501
   ```

### Scans rÃ©guliers (monitoring)

1. **Planifier un scan hebdomadaire** (cron) :
   ```bash
   # Ã‰diter crontab
   crontab -e
   
   # Ajouter (tous les lundis Ã  2h du matin)
   0 2 * * 1 /home/rgallon/server-analyzer/venv/bin/python /home/rgallon/server-analyzer/scripts/run_scan.py
   ```

2. **Comparer les scans** :
   ```bash
   # Via dashboard : Page "Comparaisons"
   # Ou CLI :
   python scripts/compare_scans.py <old_scan_id> <new_scan_id> --export
   ```

3. **Exporter les rÃ©sultats** :
   ```bash
   # Via dashboard : Page "Exports"
   # Ou CLI :
   python scripts/export_results.py --scan-id <id> --format excel
   ```

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :

1. Consulter ce guide
2. Consulter les rapports de phase (PHASE*_RAPPORT.md)
3. VÃ©rifier les logs : `logs/scan_*.log`
4. Tester la configuration : `python src/config_validator.py`

---

**Bon scan ! ğŸš€**
